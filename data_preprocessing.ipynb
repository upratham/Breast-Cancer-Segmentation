{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5161e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations import HorizontalFlip, VerticalFlip,Rotate\n",
    "from skimage import io, color, filters, restoration\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2025e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dir(path):\n",
    "    \"\"\" Create a directory. \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260b8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, filters\n",
    "\n",
    "def anisotropic_diffusion(x):\n",
    "    x = x.astype(float)\n",
    "    gradient_x = filters.sobel_h(x)\n",
    "    gradient_y = filters.sobel_v(x)\n",
    "    structure_tensor = np.array([[gradient_x**2, gradient_x * gradient_y],\n",
    "                             [gradient_x * gradient_y, gradient_y**2]])\n",
    "    iterations = 10\n",
    "    delta_t = 0.1\n",
    "    denoised_image = np.copy(x)\n",
    "    kappa=30\n",
    "    for _ in range(iterations):\n",
    "        gradient_x = filters.sobel_h(denoised_image)\n",
    "        gradient_y = filters.sobel_v(denoised_image)\n",
    "        gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "        diffusion = np.exp(-kappa * gradient_magnitude)\n",
    "        delta_x = np.roll(denoised_image, -1, axis=0) - denoised_image\n",
    "        delta_y = np.roll(denoised_image, -1, axis=1) - denoised_image\n",
    "        divergence = delta_x + delta_y\n",
    "        denoised_image += delta_t * diffusion * divergence\n",
    "        x=denoised_image\n",
    "    return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1a09698",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(path, split=0.15):\n",
    "    \"\"\" Load the images and masks \"\"\"\n",
    "    images = sorted(glob(f\"{path}/*/images/*.png\"))\n",
    "    masks = sorted(glob(f\"{path}/*/masks/*.png\"))\n",
    "\n",
    "    \"\"\" Split the data \"\"\"\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c6208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Apply CLAHE to the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5f8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def pre_process(images, masks, save_path, augment=True):\n",
    "    \"\"\" Performing data augmentation. \"\"\"\n",
    "    H = 128\n",
    "    W = 128\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "        \"\"\" Extracting the dir name and image name \"\"\"\n",
    "        dir_name = x.split(\"\\\\\")[-3]\n",
    "        name = dir_name + \"_\" + x.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Read the image and mask \"\"\"\n",
    "        x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
    "        x=cv2.GaussianBlur(x, (5,5), 0)\n",
    "       # x=anisotropic_diffusion(x)\n",
    "        #x = cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
    "#         x=cv2.equalizeHist(x)\n",
    "          #x=cv2.fastNlMeansDenoising(x, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "        #x = cv2.bilateralFilter(x, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "        \n",
    "        x = clahe.apply(x)\n",
    "        # Apply dilation\n",
    "        #x = cv2.dilate(x, kernel, iterations=1)\n",
    "        # Apply erosion\n",
    "        #x = cv2.erode(x, kernel, iterations=1)\n",
    "        y = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if augment == True:\n",
    "            aug = HorizontalFlip(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x1 = augmented[\"image\"]\n",
    "            y1 = augmented[\"mask\"]\n",
    "\n",
    "            aug = VerticalFlip(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x2 = augmented['image']\n",
    "            y2 = augmented['mask']\n",
    "\n",
    "            aug = Rotate(limit=45, p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x3 = augmented[\"image\"]\n",
    "            y3 = augmented[\"mask\"]\n",
    "\n",
    "            X = [x, x1, x2,x3]\n",
    "            Y = [y, y1, y2,y3]\n",
    "\n",
    "        else:\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "        \n",
    "\n",
    "        idx = 0\n",
    "        for i, m in zip(X, Y):\n",
    "            i = cv2.resize(i, (W, H))\n",
    "            m = cv2.resize(m, (W, H))\n",
    "#             m = m/255.0\n",
    "#             m = (m > 0.5) * 255\n",
    "\n",
    "            if len(X) == 1:\n",
    "                tmp_image_name = f\"{name}.jpg\"\n",
    "                tmp_mask_name  = f\"{name}.jpg\"\n",
    "            else:\n",
    "                tmp_image_name = f\"{name}_{idx}.jpg\"\n",
    "                tmp_mask_name  = f\"{name}_{idx}.jpg\"\n",
    "\n",
    "            image_path = os.path.join(save_path, \"image/\", tmp_image_name)\n",
    "            mask_path  = os.path.join(save_path, \"mask/\", tmp_mask_name)\n",
    "    \n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "\n",
    "\n",
    "            idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee106f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_train_test/train'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Load the dataset \"\"\"\n",
    "dataset_path = os.path.join(r\"data_raw/train\")\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c65960",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (valid_x, valid_y) = load_data(dataset_path, split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab4e43b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  539\n",
      "Valid:  94\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Train: \", len(train_x))\n",
    "print(\"Valid: \", len(valid_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7750c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_dir(\"data/train/image\")\n",
    "create_dir(\"data/train/mask/\")\n",
    "create_dir(\"data/valid/image/\")\n",
    "create_dir(\"data/valid/mask/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1df04e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:09<00:00, 57.07it/s]\n",
      "100%|██████████| 94/94 [00:01<00:00, 67.05it/s]\n"
     ]
    }
   ],
   "source": [
    "pre_process(train_x, train_y, \"data/train/\", augment=True)\n",
    "pre_process(valid_x, valid_y, \"data/valid/\", augment=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
